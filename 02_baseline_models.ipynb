{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a05aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import your evaluation framework\n",
    "# (Copy the portfolio_score and time_series_cv functions here or import them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383a84d",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./hull-tactical-market-prediction')\n",
    "train_df = pd.read_csv(DATA_PATH / 'train.csv')\n",
    "\n",
    "print(f\"Original shape: {train_df.shape}\")\n",
    "print(f\"Date range: {train_df['date_id'].min()} - {train_df['date_id'].max()}\")\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [c for c in train_df.columns if c.startswith(('M', 'E', 'I', 'P', 'V', 'S', 'MOM', 'D'))]\n",
    "target_col = 'market_forward_excess_returns'  # Normalized target\n",
    "\n",
    "print(f\"\\nFeature groups:\")\n",
    "for prefix in ['M', 'E', 'I', 'P', 'V', 'S', 'MOM', 'D']:\n",
    "    cols = [c for c in feature_cols if c.startswith(prefix)]\n",
    "    print(f\"  {prefix}*: {len(cols)} features\")\n",
    "\n",
    "print(f\"\\nTarget: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missingness over time\n",
    "train_df['missing_count'] = train_df[feature_cols].isnull().sum(axis=1)\n",
    "train_df['missing_pct'] = train_df['missing_count'] / len(feature_cols) * 100\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.scatter(train_df['date_id'], train_df['missing_pct'], s=1, alpha=0.5)\n",
    "plt.axhline(50, color='r', linestyle='--', label='50% missing')\n",
    "plt.xlabel('date_id')\n",
    "plt.ylabel('% Missing Features')\n",
    "plt.title('Missingness Over Time')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Decide on a cutoff\n",
    "CUTOFF_DATE = 1000  # Trim early sparse data\n",
    "print(f\"\\nTrimming dates < {CUTOFF_DATE}\")\n",
    "train_df = train_df[train_df['date_id'] >= CUTOFF_DATE].reset_index(drop=True)\n",
    "print(f\"New shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ace20c",
   "metadata": {},
   "source": [
    "## Model 1: ElasticNet Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05827e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_MULTIPLIER = 400.0  # Tune this!\n",
    "\n",
    "def convert_return_to_signal(predicted_return, multiplier=SIGNAL_MULTIPLIER):\n",
    "    \"\"\"\n",
    "    Map predicted return → allocation [0, 2]\n",
    "    \n",
    "    Logic:\n",
    "    - predicted_return = 0 → signal = 1.0 (neutral)\n",
    "    - positive return → > 1 (up to 2)\n",
    "    - negative return → < 1 (down to 0)\n",
    "    \"\"\"\n",
    "    signal = predicted_return * multiplier + 1.0\n",
    "    return np.clip(signal, 0.0, 2.0)\n",
    "\n",
    "class ElasticNetModel:\n",
    "    def __init__(self, signal_multiplier=400.0):\n",
    "        self.signal_multiplier = signal_multiplier\n",
    "        self.model = None\n",
    "        self.feature_cols = None\n",
    "    \n",
    "    def fit(self, train_fold):\n",
    "        self.feature_cols = [c for c in train_fold.columns \n",
    "                             if c.startswith(('M', 'E', 'I', 'P', 'V', 'S', 'MOM', 'D'))]\n",
    "        \n",
    "        X = train_fold[self.feature_cols]\n",
    "        y = train_fold['market_forward_excess_returns']\n",
    "        \n",
    "        # Drop rows with NaN target\n",
    "        mask = y.notna()\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        # Pipeline: impute → scale → ElasticNet\n",
    "        self.model = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', ElasticNetCV(\n",
    "                l1_ratio=0.5,\n",
    "                alphas=np.logspace(-4, 2, 50),\n",
    "                max_iter=100000,\n",
    "                cv=3\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, test_fold):\n",
    "        X_test = test_fold[self.feature_cols]\n",
    "        predicted_returns = self.model.predict(X_test)\n",
    "        signals = convert_return_to_signal(predicted_returns, self.signal_multiplier)\n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate ElasticNet\n",
    "def elasticnet_predict_wrapper(train_fold, test_fold):\n",
    "    model = ElasticNetModel(signal_multiplier=400.0)\n",
    "    model.fit(train_fold)\n",
    "    return model.predict(test_fold)\n",
    "\n",
    "# results_enet = time_series_cv(elasticnet_predict_wrapper, train_df, n_splits=5, test_size=180)\n",
    "# plot_cv_results(results_enet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081f840",
   "metadata": {},
   "source": [
    "## Model 2: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBMModel:\n",
    "    def __init__(self, signal_multiplier=400.0, lgb_params=None):\n",
    "        self.signal_multiplier = signal_multiplier\n",
    "        self.lgb_params = lgb_params or {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 63,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        self.model = None\n",
    "        self.feature_cols = None\n",
    "    \n",
    "    def fit(self, train_fold):\n",
    "        self.feature_cols = [c for c in train_fold.columns \n",
    "                             if c.startswith(('M', 'E', 'I', 'P', 'V', 'S', 'MOM', 'D'))]\n",
    "        \n",
    "        X = train_fold[self.feature_cols].fillna(-999)  # LGB can handle missing values\n",
    "        y = train_fold['market_forward_excess_returns']\n",
    "        \n",
    "        mask = y.notna()\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        train_set = lgb.Dataset(X, label=y)\n",
    "        self.model = lgb.train(\n",
    "            self.lgb_params,\n",
    "            train_set,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[train_set],\n",
    "            callbacks=[lgb.early_stopping(200), lgb.log_evaluation(0)]\n",
    "        )\n",
    "    \n",
    "    def predict(self, test_fold):\n",
    "        X_test = test_fold[self.feature_cols].fillna(-999)\n",
    "        predicted_returns = self.model.predict(X_test)\n",
    "        signals = convert_return_to_signal(predicted_returns, self.signal_multiplier)\n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate LightGBM\n",
    "def lgbm_predict_wrapper(train_fold, test_fold):\n",
    "    model = LGBMModel(signal_multiplier=400.0)\n",
    "    model.fit(train_fold)\n",
    "    return model.predict(test_fold)\n",
    "\n",
    "# results_lgbm = time_series_cv(lgbm_predict_wrapper, train_df, n_splits=5, test_size=180)\n",
    "# plot_cv_results(results_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0fbcbe",
   "metadata": {},
   "source": [
    "## Model 3: Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e678ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, weights=None):\n",
    "        self.weights = weights or [0.5, 0.5]  # [ElasticNet, LGBM]\n",
    "        self.model_enet = ElasticNetModel(signal_multiplier=400.0)\n",
    "        self.model_lgbm = LGBMModel(signal_multiplier=400.0)\n",
    "    \n",
    "    def fit(self, train_fold):\n",
    "        self.model_enet.fit(train_fold)\n",
    "        self.model_lgbm.fit(train_fold)\n",
    "    \n",
    "    def predict(self, test_fold):\n",
    "        pred_enet = self.model_enet.predict(test_fold)\n",
    "        pred_lgbm = self.model_lgbm.predict(test_fold)\n",
    "        \n",
    "        ensemble_pred = (\n",
    "            self.weights[0] * pred_enet +\n",
    "            self.weights[1] * pred_lgbm\n",
    "        )\n",
    "        \n",
    "        return np.clip(ensemble_pred, 0.0, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate Ensemble\n",
    "def ensemble_predict_wrapper(train_fold, test_fold):\n",
    "    model = EnsembleModel(weights=[0.3, 0.7])  # Tune these!\n",
    "    model.fit(train_fold)\n",
    "    return model.predict(test_fold)\n",
    "\n",
    "# results_ensemble = time_series_cv(ensemble_predict_wrapper, train_df, n_splits=5, test_size=180)\n",
    "# plot_cv_results(results_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f5ca2",
   "metadata": {},
   "source": [
    "## Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run full comparison\n",
    "# results = {\n",
    "#     'Constant 0.8': results_08,\n",
    "#     'Constant 1.0': results_10,\n",
    "#     'ElasticNet': results_enet,\n",
    "#     'LightGBM': results_lgbm,\n",
    "#     'Ensemble': results_ensemble\n",
    "# }\n",
    "\n",
    "# comparison_df = pd.DataFrame({\n",
    "#     'Model': list(results.keys()),\n",
    "#     'Mean Score': [r['mean_score'] for r in results.values()],\n",
    "#     'Std Score': [r['std_score'] for r in results.values()]\n",
    "# }).sort_values('Mean Score', ascending=False)\n",
    "\n",
    "# display(comparison_df)\n",
    "\n",
    "# # Plot comparison\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.barh(comparison_df['Model'], comparison_df['Mean Score'])\n",
    "# plt.xlabel('Mean CV Score')\n",
    "# plt.title('Model Comparison')\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faba0c0",
   "metadata": {},
   "source": [
    "---\n",
    "## ✅ Next Steps:\n",
    "1. Tune `SIGNAL_MULTIPLIER` for each model\n",
    "2. Tune ensemble weights\n",
    "3. Add feature engineering\n",
    "4. Create submission notebook with best model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
